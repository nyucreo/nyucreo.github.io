---
# Display name
title: Eugene Vinitsky

# Full Name (for SEO)
first_name: Eugene
last_name: Vinitsky

# Role/position
role: Assistant Professor


# Organizations/Affiliations
organizations:
  - name: New York University
    url: ''

# research interests
interests:
  - Reinforcement Learning
  - Multi-agent Learning
  - Autonomous Vehicles
  - Traffic Control
# education
# Social/Academic Networking
social:
  - icon: envelope
    icon_pack: fas
    link: 'mailto:ev2237@nyu.edu'
  - icon: google-scholar
    icon_pack: ai
    link: https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao
  - icon: globe
    icon_pack: fas
    link: https://eugenevinitsky.com/
  - icon: linkedin
    icon_pack: fab
    link: https://www.linkedin.com/in/eugenevinitsky/
  

# Highlight the author in author lists? (true/false)
highlight_name: false

user_groups:
  - Core Faculty
---

I'm an incoming Assistant Professor at NYU Tandon in 2023 based in Civil Engineering with a PhD in control from UC Berkeley with Alexandre Bayen. My research goal is to see complex, human-like behavior emerge from unsupervised interaction between groups of learning agents with an applications focus on robotics and transportation. Concretely this leads to a lot of questions I'm currently interested in:

How can we use RL to design models of human agents? How can we ensure that RL designed agents are human-compatible?
How can we synthesize environments that push and test the capabilities of our agents?
What algorithmic advances and software tools are needed to address these questions?
In practice this means working on understanding how to push the state of the art in multi-agent RL algorithms, designing new data-driven simulators, and trying to deploy simulator-designed controllers into real-world systems. For a sample of the type of work that I do / have done, check out the research section below.
I've spent time at Apple, Tesla, Deepmind, Facebook AI Research, and am a recipient of an NSF fellowship.
